# Streaming Responses

Amazing work so far! Now we are almost at the end and in this lesson, you will see our whole project in action. 

Ah, dear reader, as we embark upon this captivating journey through the heart of the code, let us, as they do in the elegant society of *Bridgerton*, lace it with grace, charm, and a touch of wit. Imagine if Lady Whistledown herself were to describe this technical process—her words would certainly sparkle with eloquence! So, let us step into the ballroom of imports, where each piece plays its part, like a finely choreographed dance.

![dance.gif](https://github.com/0xmetaschool/Learning-Projects/blob/main/assests_for_all/Build%20AI%20Dating%20Coach%20Using%20NextJS%20and%20OpenAI/L10%20Streaming%20Responses/dance.gif?raw=true)

## Imports Section

Picture this: the grand entrance to our tale. Here we find the distinguished guests, each poised to contribute to the unfolding drama with precision and purpose.

```jsx
import { authenticateSSE } from '../../../utils/auth';
import { OpenAI } from 'openai';
import User from '../../../models/User';
import Message from '../../../models/Message';
```

- **`authenticateSSE`**: Much like a discerning footman guarding the entrance to an exclusive soirée, this middleware ensures that only those with the proper credentials—authenticated users—may partake in the Server-Sent Events (SSE) connection.
- **`OpenAI`**: The heart of intelligence and sophistication, akin to the finest gentleman at the ball, this imports OpenAI’s tools, granting us access to the boundless knowledge of the GPT model.
- **`User`**: Our faithful family register, the *debutantes' ledger* of sorts, this model enables us to interact with the user collection, ensuring we know precisely who is attending.
- **`Message`**: The social correspondence! Like the love letters exchanged in secret, this model manages the delicate messages shared between the user and the assistant, recording every whispered word.

## OpenAI Instance

Ah, but what is a grand ball without the orchestration of delightful conversations? Here, we establish our *conductor*—the OpenAI instance, conducting symphonies of dialogue.

```jsx
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});
```

- An instance of OpenAI is summoned, bearing the **API key** as its personal invitation to the grand event. This key, securely held in the environment variables, grants us access to the esteemed halls of OpenAI's model.

## Main Function Export

And now, our attention shifts to the master of ceremonies, the **handler**, which is cloaked in the sophisticated armor of `authenticateSSE`, ensuring only those with proper introductions may step inside.

```jsx
export default authenticateSSE(async function handler(req, res) {
```

- Here, we introduce the main export wrapped in authentication. Only the most reputable guests—authenticated users—may enter this prestigious function.

## Check Request Method and Setup SSE Headers

Much like a keen eye inspecting invitations at the entrance to the ball, we ensure that every request is properly vetted. Only *GET* requests are permitted within these chambers, and the headers are set to maintain an elegant flow of information.

```jsx
  if (req.method === 'GET') {
    const { input } = req.query;

    res.writeHead(200, {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache, no-transform',
      'Connection': 'keep-alive',
    });
```

- **`GET` Method**: Ah, the only acceptable method of entry. Those who attempt to enter via any other means will, alas, be turned away.
- **Headers**: With the grace of a host ensuring the ambiance is just right, we set headers for an uninterrupted *flow* of communication—ensuring the event remains lively and ongoing.

## User Validation

Ah, but what if the guest of honor is nowhere to be found? Before the evening's festivities may commence, we check the registry to ensure that the user, our protagonist, is indeed present.

```jsx
    const user = await User.findById(req.userId);
    if (!user) {
      res.write(`data: ${JSON.stringify({ error: "User not found" })}\n\n`);
      res.end();
      return;
    }
```

- **User Check**: The grand registrar (our database) is consulted to ensure the user’s identity. If absent, our assistant regretfully informs them that their presence is required, and the conversation ends with a polite farewell.

## Retrieve Conversation History

Now, like a well-read social column documenting past interactions, we gather the most recent correspondences. It is only fitting to consider the past before continuing forward, is it not?

```jsx
    const lastMessages = await Message.find({ userId: req.userId })
      .sort({ timestamp: -1 })
      .limit(6);

    const conversationHistory = lastMessages.reverse().map(msg => ({
      role: msg.role,
      content: msg.content
    }));
```

- **Conversation History**: Ah, the letters of old! We retrieve the last six exchanges, carefully placing them in chronological order. These correspondences guide our assistant in offering the most well-informed counsel.

## User Context Setup

What are a few words between acquaintances, when one can present the **whole context**? Just as a skilled matchmaker would reveal vital details to prospective suitors, our assistant benefits from knowing the user's most pertinent attributes.

```jsx
    const userContext = `User Info:
    Name: ${user.name.split(' ')[0] || user.name}
    Age: ${user.age}
    Gender: ${user.gender}
    Interests: ${user.interests.join(', ')}`;
```

- **User Context**: With the refinement of a personal introduction, we provide the assistant with details on the user: their name, age, gender, and interests. This, of course, ensures the conversation remains tailored and sincere.

## Save User Input to Database

A true chronicler of society would never let a conversation slip away unrecorded! Likewise, we ensure that the user’s message is *captured* and saved in our **Message** collection.

```jsx
    await new Message({ userId: req.userId, role: 'user', content: input }).save();
```

- **Saving the Message**: The user’s input is enshrined in the grand archive of exchanges, forever to be referenced in future consultations.

## Prepare Messages for OpenAI

Ah, now we prepare the assistant for conversation! Like a finely written letter, these messages are composed with care, blending the user’s input with their personal history, and setting the stage for a wise reply.

```jsx
    const messages = [
      { role: "system", content: "You are a gentle and insightful Love Guru..." },
      { role: "user", content: userContext },
      ...conversationHistory,
      { role: "user", content: input }
    ];

```

- **Message Construction**: With a flourish, we present the assistant with its role—*a wise and insightful Love Guru*—and offer it not only the user’s recent words but also their past and the very essence of their being.

## Generate Response from OpenAI

The assistant now composes its reply, a missive drawn from the depths of OpenAI’s knowledge. But, like any good conversation, this reply arrives not all at once but in carefully measured pieces, ensuring the conversation flows naturally.

```jsx
    try {
      const stream = await openai.chat.completions.create({
        model: "gpt-4",
        messages: messages,
        stream: true,
      });

```

- **OpenAI Streaming**: The assistant, utilizing OpenAI’s vast intellect, generates its response in streaming mode. This allows for a more dynamic and timely delivery—like a dance where each step leads seamlessly to the next.

## Handle Streaming Response

As the assistant speaks, its words flow in fragments, much like a well-paced conversation at a soirée. Each remark is sent gracefully to the user in real time.

```jsx
      let assistantResponse = '';

      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || "";
        assistantResponse += content;
        res.write(`data: ${JSON.stringify({ content })}\n\n`);
      }
```

- **Streaming Response**: The assistant’s words, arriving in graceful intervals, are sent to the user, ensuring that the conversation feels fluid as if part of a grand exchange at a candlelit ball.

---

## Save Assistant Response

And finally, dear reader, just as the assistant’s advice touches the hearts of those who seek it, so too must it be captured in the annals of history, stored for future reference.

```jsx
      await new Message({ userId: req.userId, role: 'assistant', content: assistantResponse }).save();
```

- **Saving the Assistant’s Reply**: The assistant’s words are recorded, ensuring that the exchange remains part of the user’s ongoing story, one chapter in the larger narrative of their dating journey.

## Error Handling

Like all good things, the conversation must come to an end, and so too must the stream be gracefully concluded. Should an unfortunate misstep occur, we ensure that even errors are handled with care and discretion.

```jsx
      res.write(`data: ${JSON.stringify({ content: "[DONE]" })}\n\n`);
      res.end();
    } catch (error) {
      console.error('Error in SSE stream:', error);
      res.write(`data: ${JSON.stringify({ error: "Error generating advice" })}\n\n`);
      res.end();
    }

```

- **Closing the Conversation**: The assistant bids its farewell with a final `[DONE]`, ensuring the user knows the conversation has reached its natural conclusion. Should any error occur, it is
- If an error occurs during the process, it sends an error message via SSE and logs the error to the console.

## Front-end Interaction

We are now ready with our final version of the code! Now is the time to check the code! Simply run the following commands and see the magic!

```
npm install
npm run dev
```

And you will see an output at [http://localhost:3000/](http://localhost:3000/). 

Let’s try to signup first and then ask away the questions.

![final_ai_dating.gif](https://github.com/0xmetaschool/Learning-Projects/blob/main/assests_for_all/Build%20AI%20Dating%20Coach%20Using%20NextJS%20and%20OpenAI/L10%20Streaming%20Responses/final_ai_dating.gif?raw=true)

Yayyyy, it’s working! And we are finally done with our code.  Doesn’t it feel amazing!!

## Pushing it to Git

Make sure you are in the `dating-ai-bot-app` folder. Remember to push your code to your GitHub repository using the following commands. 

```solidity
git add .
git commit -m "the dating ai coach app is successfully working"
git push
```

## Wrap-Up

Congratulations on sticking till the end! You have done a great job. You should be proud of yourself for this achievement. Now, let’s deploy our project on vercel so that you can show everyone what you have built! Excited? See you in the next lesson!
